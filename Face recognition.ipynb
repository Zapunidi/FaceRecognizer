{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\z000rkxc\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\z000rkxc\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\z000rkxc\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\z000rkxc\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\z000rkxc\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\z000rkxc\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "C:\\Users\\z000rkxc\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\z000rkxc\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\z000rkxc\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\z000rkxc\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\z000rkxc\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\z000rkxc\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\z000rkxc\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:4070: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "from mtcnn.mtcnn import MTCNN\n",
    "from os import listdir, makedirs\n",
    "from os.path import join\n",
    "from PIL import Image\n",
    "from pyautogui import prompt\n",
    "import cv2\n",
    "import numpy as np\n",
    "import time\n",
    "import math\n",
    "from sklearn.svm import SVC\n",
    "import pickle\n",
    "from IPython.display import clear_output\n",
    "np.set_printoptions(suppress=True)\n",
    "\n",
    "detector = MTCNN()\n",
    "embedding_size = 128\n",
    "\n",
    "def l2_normalize(x, axis=-1, epsilon=1e-10):\n",
    "    output = x / np.sqrt(np.maximum(np.sum(np.square(x), axis=axis, keepdims=True), epsilon))\n",
    "    return output\n",
    "\n",
    "def loadImage(filepath):\n",
    "    # load image from file\n",
    "    image = Image.open(filepath)\n",
    "    image = image.convert('RGB')\n",
    "    pixels = np.asarray(image)\n",
    "    \n",
    "    return pixels\n",
    "\n",
    "def normalizeImage(image):\n",
    "    mean, std = image.mean(), image.std()\n",
    "    image = (image - mean) / std\n",
    "    return image\n",
    "\n",
    "def denormalizeImage(image):\n",
    "    image = image - image.min()\n",
    "    image = image / image.max()*255\n",
    "    \n",
    "    return image.astype(np.uint8)\n",
    "\n",
    "def randomHSVShifts(image, shift_value=40):\n",
    "    image = denormalizeImage(image)\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_RGB2HSV).astype(np.int32)\n",
    "    image[:, :, 0] += np.random.randint(-shift_value, shift_value)\n",
    "    image[:, :, 1] += np.random.randint(-shift_value, shift_value)\n",
    "    image[:, :, 2] += np.random.randint(-shift_value, shift_value)\n",
    "    image = np.clip(image, 0, 255)\n",
    "    image = cv2.cvtColor(image.astype(np.uint8), cv2.COLOR_HSV2RGB)\n",
    "    image = normalizeImage(image)\n",
    "    return image\n",
    "    \n",
    "def extractFaces(image, normalize=True):\n",
    "    results = detector.detect_faces(image)\n",
    "    faces = np.zeros((0, 160, 160, 3), dtype=np.float32)\n",
    "    coords = np.zeros((0, 4), dtype=np.int32)\n",
    "    for i in range(len(results)):\n",
    "        x1, y1, w, h = results[i]['box']\n",
    "        x1 = abs(x1)\n",
    "        y1 = abs(y1)\n",
    "        w = abs(w)\n",
    "        h = abs(h)\n",
    "        face = image[y1:(y1+h), x1:(x1+w)]\n",
    "        if face.shape[0]*face.shape[1]*face.shape[2] == 0:\n",
    "            continue\n",
    "        img = Image.fromarray(face)\n",
    "        img = img.resize((160, 160))\n",
    "        face = np.asarray(img)\n",
    "        if normalize:\n",
    "            face = normalizeImage(face)\n",
    "        faces = np.append(faces, np.expand_dims(face, axis=0), axis=0)\n",
    "        rect_coords = np.array([x1, y1, x1+w, y1+h]).reshape(1, 4)\n",
    "        coords = np.append(coords, rect_coords, axis=0)\n",
    "    return faces, coords\n",
    "\n",
    "class Predictor:\n",
    "    def __init__(self, model_path, face_database_path, classifier_path=None, identities_path=None, unbalanced=True):\n",
    "        self.unknown_thresh = 0.3\n",
    "        self.N_aug = 5\n",
    "        self.model = load_model(model_path)\n",
    "        self.face_database_path = face_database_path\n",
    "        if identities_path is not None:\n",
    "            self.identities = self.loadIdentities(identities_path)\n",
    "        if classifier_path is not None:\n",
    "            self.classifier = self.loadClassifier(classifier_path)\n",
    "        else:\n",
    "            print(\"Processing the database...\")\n",
    "            X, y = self.processDatabase(face_database_path)\n",
    "            class_weights = self.computeClassWeights(y)\n",
    "            print(class_weights)\n",
    "            print(\"Processing finished\")\n",
    "            self.classifier = SVC(kernel='linear', probability=True, class_weight=class_weights)\n",
    "            self.classifier.fit(X, y)\n",
    "            self.X = X\n",
    "            self.y = y\n",
    "            self.saveIdentities(\"./identities_dict.pickle\", self.identities)\n",
    "            self.saveClassifier(\"./classifier.pickle\", self.classifier)\n",
    "            cv2.namedWindow('Detections')\n",
    "            cv2.setMouseCallback('Detections', self.addNewIdentity)\n",
    "    \n",
    "    def processDatabase(self, face_database_path, detect_faces=True):\n",
    "        folders = [join(face_database_path, f) for f in listdir(face_database_path)]\n",
    "        names = []\n",
    "        embeddings = np.zeros((0, embedding_size))\n",
    "        for folder in folders:\n",
    "            files = [join(folder, f) for f in listdir(folder)]\n",
    "            for file in files:\n",
    "                image = loadImage(file)\n",
    "                if detect_faces:\n",
    "                    faces, coords = extractFaces(image, normalize=False)\n",
    "                    if faces.shape[0] == 0:\n",
    "                        continue\n",
    "                    image = faces[0]\n",
    "                name = folder.split(\"\\\\\", 1)[1]\n",
    "                image = cv2.resize(image, (160, 160))\n",
    "                image = normalizeImage(image)\n",
    "                embedding = self.computeEmbeddings(image)\n",
    "                embeddings = np.append(embeddings, embedding, axis=0)\n",
    "                names.append(name)\n",
    "        embeddings = l2_normalize(embeddings)\n",
    "        labels, self.identities = self.toCategorical(names)\n",
    "        return embeddings, labels\n",
    "    \n",
    "    def toCategorical(self, str_arr):\n",
    "        values = list(set(str_arr))\n",
    "        keys = list(range(len(values)))\n",
    "        str_to_cat = dict(zip(values, keys))\n",
    "        cat_to_str = dict(zip(keys, values))\n",
    "        \n",
    "        categorical = np.array([str_to_cat[string] for string in str_arr], dtype=np.int32)\n",
    "        \n",
    "        return categorical, cat_to_str\n",
    "    \n",
    "    def computeClassWeights(self, labels):\n",
    "        unique = np.unique(labels)\n",
    "        weights = {}\n",
    "        for i in range(unique.shape[0]):\n",
    "            label = unique[i]\n",
    "            weight = 1 / labels[labels==label].shape[0]\n",
    "            weights[label] = weight\n",
    "        return weights\n",
    "    \n",
    "    def computeEmbeddings(self, images):\n",
    "        return self.model.predict(images.reshape(-1, 160, 160, 3))\n",
    "    \n",
    "    def saveClassifier(self, path, classifier):\n",
    "        with open(path, 'wb') as f:\n",
    "            pickle.dump(classifier, f)\n",
    "            \n",
    "    def loadClassifier(self, path):\n",
    "        with open(path, 'rb') as f:\n",
    "            classifier = pickle.load(f)\n",
    "        return classifier\n",
    "    \n",
    "    def saveIdentities(self, path, identities):\n",
    "        with open(path, 'wb') as f:\n",
    "            pickle.dump(identities, f)            \n",
    "        \n",
    "    def loadIdentities(self, path):\n",
    "        with open(path, 'rb') as f:\n",
    "            identities = pickle.load(f)\n",
    "        return dict(identities)\n",
    "    \n",
    "    def saveConfig(self, clf_path, id_path):\n",
    "        self.saveClassifier(clf_path, self.classifier)\n",
    "        self.saveIdentities(id_path, self.identities)\n",
    "        \n",
    "    def predictFaces(self, image):\n",
    "        faces, coords = extractFaces(image)\n",
    "        if faces.shape[0] == 0:\n",
    "            return image\n",
    "        emb = self.computeEmbeddings(faces)\n",
    "        emb = l2_normalize(emb)\n",
    "        clear_output(wait=True)\n",
    "        classes = self.classifier.predict(emb)\n",
    "        probs = self.classifier.predict_proba(emb)\n",
    "        self.coords = coords\n",
    "        self.faces = faces\n",
    "        for i in range(classes.shape[0]):\n",
    "            image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "            cv2.rectangle(image, (coords[i, 0], coords[i, 1]), (coords[i, 2], coords[i, 3]), (0, 255, 0), 2)\n",
    "            clear_output(wait=True)\n",
    "            if np.max(probs[i]) < self.unknown_thresh:\n",
    "                label = \"Unknown person\"\n",
    "            else:\n",
    "                label = self.identities[classes[i]]\n",
    "            cv2.putText(image, label, (coords[i, 0], coords[i, 1]-10), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)\n",
    "        cv2.imshow(\"Detections\", image)  \n",
    "        \n",
    "    def inRectangle(self, x, y):\n",
    "        rect_idx = None\n",
    "        if self.coords is None:\n",
    "            return rect_idx\n",
    "        for i in range(self.coords.shape[0]):\n",
    "            x1, y1, x2, y2 = self.coords[i]\n",
    "            if x > x1 and x < x2 and y > y1 and y < y2:\n",
    "                rect_idx = i\n",
    "                return rect_idx\n",
    "    \n",
    "    def addNewIdentity(self, event, x, y, flags, param):\n",
    "        rect_idx = self.inRectangle(x, y)\n",
    "        if event == cv2.EVENT_LBUTTONDBLCLK and rect_idx is not None:\n",
    "            name = prompt(text='Enter the name of this person', title='Add new face image' , default='')\n",
    "            if name is None:\n",
    "                return\n",
    "            if name in self.identities.values():\n",
    "                identities_to_number = dict([(value, key) for key, value in self.identities.items()]) \n",
    "                class_number = identities_to_number[name]\n",
    "                new_identity = False\n",
    "            else:\n",
    "                class_number = np.max(self.y) + 1\n",
    "                makedirs(self.face_database_path+\"/\"+name)\n",
    "                self.identities.update({class_number: name})\n",
    "                new_identity = True\n",
    "            if new_identity:\n",
    "                for i in range(self.N_aug):\n",
    "                    face_img = self.faces[rect_idx] \n",
    "                    face_img = randomHSVShifts(face_img)\n",
    "                    emb = l2_normalize(self.computeEmbeddings(face_img))\n",
    "                    # Appending embeddings and labels\n",
    "                    self.X = np.append(self.X, emb, axis=0)\n",
    "                    self.y = np.append(self.y, class_number.reshape(1,), axis=0)\n",
    "                    # Saving the image to the database\n",
    "                    tosave = cv2.cvtColor(denormalizeImage(face_img), cv2.COLOR_RGB2BGR)\n",
    "                    cv2.imwrite(self.face_database_path+\"/\"+name+\"/\"+name+str(self.y[self.y==class_number].shape[0])+\".jpg\", tosave)\n",
    "            else:\n",
    "                face_img = self.faces[rect_idx]\n",
    "                emb = l2_normalize(self.computeEmbeddings(face_img))\n",
    "                # Appending embeddings and labels\n",
    "                self.X = np.append(self.X, emb, axis=0)\n",
    "                self.y = np.append(self.y, class_number.reshape(1,), axis=0)\n",
    "                # Saving the image to the database\n",
    "                tosave = cv2.cvtColor(denormalizeImage(face_img), cv2.COLOR_RGB2BGR)\n",
    "                cv2.imwrite(self.face_database_path+\"/\"+name+\"/\"+name+str(self.y[self.y==class_number].shape[0])+\".jpg\", tosave)\n",
    "            # Retraining the classifier\n",
    "            class_weights = self.computeClassWeights(self.y)\n",
    "            self.classifier = SVC(kernel='linear', probability=True, class_weight=class_weights)\n",
    "            self.classifier.fit(self.X, self.y)\n",
    "            \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in save file: the model was *not* compiled. Compile it manually.\n",
      "Processing the database...\n",
      "WARNING:tensorflow:From C:\\Users\\z000rkxc\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "{0: 0.07142857142857142, 1: 0.058823529411764705, 2: 0.05263157894736842, 3: 0.047619047619047616, 4: 0.045454545454545456}\n",
      "Processing finished\n"
     ]
    }
   ],
   "source": [
    "model_path = 'models/facenet_keras.h5'\n",
    "train_path = 'data/train'\n",
    "clf_path = \"classifier.pickle\"\n",
    "id_path = \"identities_dict.pickle\"\n",
    "\n",
    "system = Predictor(model_path, train_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "system.predictFaces(loadImage(\"data/maxresdefault.jpg\"))\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from IPython.display import clear_output\n",
    "import cv2\n",
    "import time\n",
    "system.unknown_thresh = 0.3\n",
    "cap = cv2.VideoCapture(\"data/bigshort.mp4\")\n",
    "\n",
    "while(True):\n",
    "    # Capture frame-by-frame\n",
    "    ret, frame = cap.read()\n",
    "    if ret:\n",
    "        frame = cv2.resize(frame, (640, 480))\n",
    "        system.predictFaces(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB))\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flags = [i for i in dir(cv2) if i.startswith('COLOR_')]\n",
    "print( flags )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
